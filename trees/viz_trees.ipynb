{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tree Models from Scratch\n",
                "\n",
                "This notebook demonstrates the usage of `DecisionTree`, `RandomForest`, and `XGBoostScratch` implemented from scratch using NumPy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from trees import DecisionTree, RandomForest, XGBoostScratch\n",
                "from sklearn.datasets import load_iris, make_regression\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Classification with Decision Tree and Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = load_iris()\n",
                "X, y = data.data, data.target\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Decision Tree\n",
                "dt = DecisionTree(max_depth=10)\n",
                "dt.fit(X_train, y_train)\n",
                "dt_preds = dt.predict(X_test)\n",
                "print(f\"Decision Tree Accuracy: {np.mean(dt_preds == y_test):.4f}\")\n",
                "\n",
                "# Random Forest\n",
                "rf = RandomForest(n_trees=5, max_depth=10)\n",
                "rf.fit(X_train, y_train)\n",
                "rf_preds = rf.predict(X_test)\n",
                "print(f\"Random Forest Accuracy: {np.mean(rf_preds == y_test):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Regression with XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "xgb = XGBoostScratch(n_estimators=20, learning_rate=0.1, max_depth=3)\n",
                "xgb.fit(X_train, y_train)\n",
                "preds = xgb.predict(X_test)\n",
                "\n",
                "plt.scatter(X_test, y_test, label=\"True\")\n",
                "plt.scatter(X_test, preds, label=\"Pred\")\n",
                "plt.title(\"XGBoost Regression\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}