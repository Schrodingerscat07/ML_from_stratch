# linear_regression_numpy.py

import numpy as np
import matplotlib.pyplot as plt 

class LinearRegression:
    """
    A simple Linear Regression model implemented from scratch using NumPy.
    This model uses "Gradient Descent" to find the optimal parameters.
    """
    def __init__(self, learning_rate=0.01, n_iters=1000):
        """
        Initializes the Linear Regression model.

        Args:
            learning_rate (float): The step size for gradient descent updates.
            n_iters (int): The number of iterations to run gradient descent.
        """
        self.lr = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        """
        Trains the linear regression model using the training data.

        Args:
            X (np.ndarray): Training data features of shape (n_samples, n_features).
            y (np.ndarray): Target values of shape (n_samples,).
        """
        # 1. Initialize parameters
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        # 2. Gradient Descent
        for _ in range(self.n_iters):
            # Calculate the predictions (linear equation)
            # y_pred = w*X + b
            y_predicted = np.dot(X, self.weights) + self.bias

            # Calculate the gradients
            # partial derivative of cost function w.r.t weights and bias
            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)

            # Update the parameters
            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        """
        Makes predictions on new data using the trained model.

        Args:
            X (np.ndarray): New data features of shape (n_samples, n_features).

        Returns:
            np.ndarray: Predicted values.
        """
        return np.dot(X, self.weights) + self.bias